{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "copyright"
      },
      "source": [
        "#### Copyright 2019 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7PLP9Q30PKtv",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f5W9rkuBmBu9"
      },
      "source": [
        "# Using APIs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zIykBQbYXrXA"
      },
      "source": [
        "In this module we will practice pulling and parsing data using a restricted public API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G8u2lYRWbE37"
      },
      "source": [
        "## Web Crawling and Scraping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-Vi3O347bIWz"
      },
      "source": [
        "**Why do we need to crawl the web?  Aren't there datasets out there?**\n",
        "\n",
        "There are datasets to learn, and conduct research on, but the best experiments and models are tested on new data.  Since new data is constantly being created on the internet, data collection is always in demand.  \n",
        "\n",
        "**How are datasets created in the first place?**\n",
        "\n",
        "The answer is through a process of manual labeling.  [Mechanical Turk](https://www.mturk.com/) is a service that allows you to crowdsource data labeling, amongst other tasks. Another way to obtain labeled data is through web crawling and scraping.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_RxMqdryDNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install spotipy library to access Spotify API\n",
        "!pip install spotipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXzrC3CtyQxF",
        "colab_type": "text"
      },
      "source": [
        "## Set up your Spotify API key\n",
        "\n",
        "1. Navigate to https://developer.spotify.com/dashboard/.\n",
        "\n",
        "2. Create a ***free*** Spotify account if you don't have one.\n",
        "3. Register an application under your account.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "374rb2ybzoXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SPOTIPY_CLIENT_ID = \"your_id_here\" #your client ID from Spotify\n",
        "SPOTIPY_CLIENT_SECRET = \"your_secret_here\" #your client secret from Spotify \n",
        "REDIRECT_URI = \"http://localhost:8888/callback\"\n",
        "SCOPE = {\n",
        "    \"account\": \"user-read-private\",\n",
        "    \"top\": \"user-top-read\",\n",
        "    \"email\": \"user-read-email\",\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjFaAvSoxve7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "from spotipy import Spotify"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpqXBpdtyOQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "client_credentials_manager = SpotifyClientCredentials(\n",
        "    client_id=SPOTIPY_CLIENT_ID, client_secret=SPOTIPY_CLIENT_SECRET)\n",
        "sp = Spotify(client_credentials_manager=client_credentials_manager)\n",
        "sp.trace=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSlwjJ2j56Ri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Download and artist image\n",
        "\n",
        "from PIL import Image\n",
        "from urllib.request import urlretrieve\n",
        "from IPython.display import Image\n",
        "\n",
        "def get_image_url(name):\n",
        "  results = sp.search(q='artist:' + name, type='artist')\n",
        "  items = results['artists']['items']\n",
        "  if len(items) > 0:\n",
        "      artist = items[0]\n",
        "      url = artist['name'], artist['images'][0]['url']\n",
        "      return url\n",
        "  else:\n",
        "    return \"no response\"\n",
        "\n",
        "artist_name = 'eminem' #@param {type:\"string\"}\n",
        "url = get_image_url(artist_name)[1]\n",
        "\n",
        "file_name = 'downloaded_image.jpg'\n",
        "urlretrieve(url, file_name)\n",
        "Image(filename=file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8HAlQEAEyXk",
        "colab_type": "text"
      },
      "source": [
        "## Find a track title from an album and download lyrics\n",
        "\n",
        "1. Query artist of interest\n",
        "2. Query albums from that artist\n",
        "3. Query songs from an album"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7-ul5nGFYX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Download track titles from an album\n",
        "\n",
        "from PIL import Image\n",
        "from urllib.request import urlretrieve\n",
        "from IPython.display import Image\n",
        "\n",
        "def get_artists(name):\n",
        "  results = sp.search(q='artist:' + name, type='artist')\n",
        "  items = results['artists']['items']\n",
        "  if len(items) > 0:\n",
        "      artist = items[0]\n",
        "      return artist\n",
        "  else:\n",
        "    return \"no response\"\n",
        "\n",
        "artist_name = 'billie eilish' #@param {type:\"string\"}\n",
        "artists = get_artists(artist_name)\n",
        "\n",
        "print(artists['uri'])\n",
        "\n",
        "def get_albums(uri):\n",
        "  results = sp.artist_albums(uri)\n",
        "  return results  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN7pUgYNVbB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = sp.artist_albums(artists['uri'], album_type='album')\n",
        "albums = results['items']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6rBHdelVyRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "while results['next']:\n",
        "  results = sp.next(results)\n",
        "  albums.extend(results['items'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svNyJxRUUffy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "album_names = [(item['name'], item['uri']) for item in albums]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu8TgI_Jf74k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tracks(album_id):\n",
        "  results = sp.album_tracks(album_id)\n",
        "  return results\n",
        "\n",
        "tracks = get_tracks(albums[0]['id'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLW2PD9KfYI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_track_names(tracks):\n",
        "  return [tracks['items'][i]['name'] for i in range(len(tracks['items']))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR5tcaoPgn4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "track_names = get_track_names(tracks)\n",
        "track_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5LdJk9Kh0gx",
        "colab_type": "text"
      },
      "source": [
        "## Query Genius API for song lyrics\n",
        "\n",
        "https://genius.com/developers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HG8Iy4RmIFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "def request_song_info(song_title, artist_name):\n",
        "  base_url = 'https://api.genius.com'\n",
        "  headers = {'Authorization': 'Bearer ' + 'h3dXZsiA82uG64McuHwx1KaUv7rNrD02q7pWjLP_Lao76IN3QWQpTm8xEpPSxdyX'}\n",
        "  search_url = base_url + '/search'\n",
        "  data = {'q': song_title + ' ' + artist_name}\n",
        "  response = requests.get(search_url, data=data, headers=headers)\n",
        "\n",
        "  return response"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4hKEHwHnxAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Query the Genius API\n",
        "artist_name = artists['name']\n",
        "song_title = track_names[1] # play around with this number to change the song\n",
        "response = request_song_info(song_title, artist_name)\n",
        "\n",
        "json = response.json()\n",
        "remote_song_info = None\n",
        "\n",
        "for hit in json['response']['hits']:\n",
        "  if artist_name.lower() in hit['result']['primary_artist']['name'].lower():\n",
        "    remote_song_info = hit\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OnpWZCJDDf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "remote_song_info"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h0QZFYer75p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract lyrics from URL if the song was found\n",
        "if remote_song_info:\n",
        "  song_url = remote_song_info['result']['url']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKuagV7_s5K7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use bs4 to parse lyrics from html\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_song_url(url):\n",
        "  page = requests.get(url)\n",
        "  html = BeautifulSoup(page.text, 'html.parser')\n",
        "  lyrics = html.find('div', class_='lyrics').get_text()\n",
        "\n",
        "  return lyrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c8n5jMYs_7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lyrics = scrape_song_url(song_url)\n",
        "print(lyrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtRMwLyZmU_c",
        "colab_type": "text"
      },
      "source": [
        "## Write the lyrics to CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL8LxCtV2L3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'artist_name': artist_name, \n",
        "    'song_title': song_title,\n",
        "    'lyrics': lyrics,\n",
        "}\n",
        "\n",
        "df = pd.DataFrame([data])\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCBKY5izJpBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv(f'{artist_name}_{song_title}.csv', header=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG12ODtFX6Xj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5WFLU7hWbO8_"
      },
      "source": [
        "# Resources\n",
        "\n",
        "* [BS4](https://www.crummy.com/software/BeautifulSoup/bs4/doc/): A Python library for parsing html documents.\n",
        "\n",
        "* [Spotipy](https://spotipy.readthedocs.io/en/latest/#installation): a Python wrapper for the spotify API.\n",
        "\n",
        "* [Genius](https://genius.com/api-clients): An API library for music lyrics and other metadata."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Swt2fxm-fG_B"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iWq38ASlb2aX"
      },
      "source": [
        "Download all the lyrics from your favorite album."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CYZEXNK1VDIJ"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TI_WxOyjcfNu",
        "colab": {}
      },
      "source": [
        "# Your answer goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-1-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-1-solution-1"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APK8hXvUkzPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "artist_name = 'the strokes'\n",
        "album_name = 'room on fire'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x73sZA2xlEeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "albums[0]['name']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AKb-7oqrcfox",
        "colab": {}
      },
      "source": [
        "# Get all albums by The Strokes.\n",
        "artist = get_artists(artist_name)\n",
        "albums = get_albums(artist['uri'])['items']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnFgo_Wjk32j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find the album we are interested in.\n",
        "my_favorite_album = None\n",
        "\n",
        "for album in albums:\n",
        "  if album['name'].lower() == album_name.lower():\n",
        "    my_favorite_album = album['id']\n",
        "    print('We found your favorite album \"%s\".' % album_name)\n",
        "    break\n",
        "\n",
        "if my_favorite_album is None:\n",
        "  print('We couldn\\'t find your favorite album, sorry.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CyZGFUjf4OZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tracks = get_tracks(my_favorite_album)\n",
        "track_names = get_track_names(tracks)\n",
        "track_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5_5tRohg54m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Query the Genius API for the song info for all songs and get their lyrics.\n",
        "# Store the lyrics in a dict, keyed by song name.\n",
        "\n",
        "# This cell may take a few minutes to run.\n",
        "import time\n",
        "\n",
        "lyrics_dict = {}\n",
        "\n",
        "for song_title in track_names:\n",
        "  response = request_song_info(song_title, artist_name)\n",
        "\n",
        "  json = response.json()\n",
        "  remote_song_info = None\n",
        "\n",
        "  for hit in json['response']['hits']:\n",
        "    if artist_name.lower() in hit['result']['primary_artist']['name'].lower():\n",
        "      remote_song_info = hit\n",
        "      break\n",
        "  \n",
        "  if remote_song_info:\n",
        "    song_url = remote_song_info['result']['url']\n",
        "  \n",
        "  lyrics_dict[song_title] = scrape_song_url(song_url)\n",
        "  # Let Genius and BS4 rest for 2 seconds!\n",
        "  time.sleep(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e4dAlc9hvPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(lyrics_dict['Reptilia'])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Copy_of_Web_Crawling_and_Scraping_Part_1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "copyright"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}