{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification with TensorFlow",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "copyright",
        "exercise-4-key-1"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "copyright"
      },
      "source": [
        "#### Copyright 2019 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BX4BkCSEPV26",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eXugJRE9PcpT"
      },
      "source": [
        "# Classification with TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KrDw3-6MIhhJ"
      },
      "source": [
        "By now, you should be familiar with classification in scikit-learn. In this colab, we will explore another commonly used tool for classification and machine learning: TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KrIzFCmyQgTk"
      },
      "source": [
        "## Load the Dataset\n",
        "\n",
        "The dataset we will be using comes packaged with scikit-learn. It is called the [MNIST Digits](https://en.wikipedia.org/wiki/MNIST_database) dataset, a large collection of hand-drawn digitzs. We load the dataset with `load_digits`, and the returned object is a scikit-learn bunch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D3gv69usIX2p",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "digits_bunch = load_digits()\n",
        "digits_bunch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qqgW9Tn-Qeys"
      },
      "source": [
        "## Bunch to DataFrame\n",
        "\n",
        "We'll convert the scikit-learn `Bunch` into a Pandas `DataFrame` for ease of processing.\n",
        "\n",
        "Columns 0 through 63 are the intensities of the pixels in the digit drawings and the *digit* column is the digit that is represented by the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TdnQOZhJIc8Y",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "digits_df = pd.DataFrame(digits_bunch.data)\n",
        "digits_df['digit'] = digits_bunch.target\n",
        "digits_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oT0OsRCyRVxL"
      },
      "source": [
        "## Examine the Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z6pFK70BR3SO"
      },
      "source": [
        "Let's take a quick look at our dataset. With `describe`, we can see that each pixel column seems to range between 0.0 and 16.0, with some columns having a smaller maximum value.\n",
        "\n",
        "The *digit* column contains the labels/targets that we are interested in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z5tjUMy5RodF",
        "colab": {}
      },
      "source": [
        "digits_df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xsxZ5StLTZwW"
      },
      "source": [
        "Let's group the data by digit and count the number of occurrences of each digit. That way, we can see that the digits are discrete values between 0 and 9, and that the number of samples of each digit is roughly equal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C6CPq6LMS3bq",
        "colab": {}
      },
      "source": [
        "digits_df.groupby('digit')['digit'].agg('count')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L9eKiqQxC2_f"
      },
      "source": [
        "## Normalize the Data\n",
        "\n",
        "The pixel values for each image ranged from 0.0 to as much as 16.0. For many machine learning models, higher values in feature data have a larger impact over the model. In this case, it would mean giving much more weight to darker pixels.\n",
        "\n",
        "An easy way to proactively prevent this is to normalize the feature data between 0.0 and 1.0. This can be done by dividing by the maximum value, 16.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JfDpLbpT9G16",
        "colab": {}
      },
      "source": [
        "digits_df.update(digits_df[digits_df.columns[0:64]] / 16.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czeY3I-PaPYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ensure that the feature data is now normalized.\n",
        "digits_df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rzhBK2Q5Tqwi"
      },
      "source": [
        "## Train/Test Split\n",
        "\n",
        "We can now time to perform a train/test split on the data so that we can train a model in TensorFlow while retaining some data to test the model with.\n",
        "\n",
        "Since the digits are evenly distributed, we will create a stratified test sample using scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "35qreT5AUE51",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(\n",
        "  digits_df,\n",
        "  stratify=digits_df['digit'],  \n",
        "  test_size=0.2,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zy90I_hhUWgB",
        "colab": {}
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hut50N6nUj_0",
        "colab": {}
      },
      "source": [
        "test_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d2A2s__6UmlQ"
      },
      "source": [
        "Verify the stratification for training data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8USmp4hUpAk",
        "colab": {}
      },
      "source": [
        "train_df.groupby('digit')['digit'].agg('count')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1eNfzw0TUwE3"
      },
      "source": [
        "And for the testing data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZJnaDmwiUxp_",
        "colab": {}
      },
      "source": [
        "test_df.groupby('digit')['digit'].agg('count')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YnD33_86Vzhv"
      },
      "source": [
        "The splits look pretty even across digits. Our stratification seems to have worked!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FCEleUTrV60T"
      },
      "source": [
        "## Feature Columns\n",
        "\n",
        "We can now build a TensorFlow model for classification. The first step is to declare our feature columns. In this case, the features are the 64 pixel intensities.\n",
        "\n",
        "Writing out 64 lines of code, one per pixel would be tedious and error-prone. An easy route to create the feature columns is to loop though the 64 columns and append them to a `feature_columns` array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EzHDvZddbEX6",
        "colab": {}
      },
      "source": [
        "from tensorflow.feature_column import numeric_column\n",
        "\n",
        "feature_columns = []\n",
        "\n",
        "for column_name in digits_df.columns[:-1]:\n",
        "  feature_columns.append(numeric_column(str(column_name)))\n",
        "\n",
        "feature_columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TGpishvKXTlH"
      },
      "source": [
        "## Classes\n",
        "\n",
        "We have 10 classes, one for each digit 0-9. We could hardcode the value 10, but instead it is better practice to count the number of unique targets we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vB99WePIKNWn",
        "colab": {}
      },
      "source": [
        "class_count = len(digits_df['digit'].unique())\n",
        "\n",
        "class_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UBfdXuiUXnGm"
      },
      "source": [
        "## Create a Classifier\n",
        "\n",
        "We now know our feature columns (the 64 pixel intensities) and know how many classes we need to identify (10). To build the classifier, we feed that data into the object constructor. In this case, we will use a [LinearClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z15ajH4hX9V7",
        "colab": {}
      },
      "source": [
        "from tensorflow.estimator import LinearClassifier\n",
        "\n",
        "classifier = LinearClassifier(feature_columns=feature_columns, n_classes=class_count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4q3mNF1JYHGE"
      },
      "source": [
        "## Train the Classifier\n",
        "\n",
        "The next step is to train the classifier. To do that we need to create an input function to feed data to the classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nl2O6oUfKWwY",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.data import Dataset\n",
        "\n",
        "def training_input():\n",
        "  features = {}\n",
        "  for i in range(64):\n",
        "    features[str(i)] = train_df[i]\n",
        " \n",
        "  labels = train_df['digit']\n",
        "\n",
        "  training_ds = Dataset.from_tensor_slices((features, labels))\n",
        "  training_ds = training_ds.shuffle(buffer_size=10000)\n",
        "  training_ds = training_ds.batch(100)\n",
        "  training_ds = training_ds.repeat(5)\n",
        "\n",
        "  return training_ds\n",
        "\n",
        "classifier.train(training_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W5SC8so793WG"
      },
      "source": [
        "What was the final loss? The TensorFlow `LinearRegressor` loss is calculated by using [softmax cross entropy](https://deepnotes.io/softmax-crossentropy)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aGMoDbWxYkln"
      },
      "source": [
        "## Make Test Predictions\n",
        "\n",
        "The next step is to make some test predictions. For this we need to create an input function that returns features. These features shouldn't be shuffled or repeated.\n",
        "\n",
        "The result is an iterator over predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_MOu4mI4L8GP",
        "colab": {}
      },
      "source": [
        "def testing_input():\n",
        "  features = {}\n",
        "  for i in range(64):\n",
        "    features[str(i)] = test_df[i]\n",
        "  return Dataset.from_tensor_slices((features)).batch(1)\n",
        "\n",
        "predictions_iterator = list(classifier.predict(testing_input))\n",
        "\n",
        "predictions_iterator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E8b8rkgHZKJO"
      },
      "source": [
        "## Examine the Predictions\n",
        "\n",
        "The predictions returned from the classifier are Python dictionaries containing four keys: 'logits', 'probabilities', 'class_ids', and 'classes'.\n",
        "\n",
        "- The 'class_ids' and 'classes' are lists containing the classes that seem probable to the model.\n",
        "\n",
        "- The 'probabilities' value contains the probabilities that each class applies to the data point. The higher the probability, the more likely the class is applicable.\n",
        "\n",
        "- The 'logits' column reflects the [logit](https://en.wikipedia.org/wiki/Logit) values for the prediction where the best value approaches 1.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mcdps2aPNO3P",
        "colab": {}
      },
      "source": [
        "for p in predictions_iterator:\n",
        "  print(p.keys())\n",
        "  print(p['logits'])\n",
        "  print(p['probabilities'])\n",
        "  print(p['class_ids'])\n",
        "  print(p['classes'])\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7E1vMIH4a6WH"
      },
      "source": [
        "You can run the code above a few times to examine predictions one-by-one.\n",
        "\n",
        "We'll re-run some code to create and train the model again in order to reset it for statistical evaluation and then extract the predictions into an array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aj-IX_iKEyym",
        "colab": {}
      },
      "source": [
        "predictions_iterator = classifier.predict(testing_input)\n",
        "\n",
        "predictions = [p['class_ids'][0] for p in predictions_iterator]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zDpWnc4MGW8v"
      },
      "source": [
        "Using these predictions, we can calculate the precision..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rMVp3qznGPpE",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "precision_score(test_df['digit'], predictions, average='micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ExXd_59OGZ8s"
      },
      "source": [
        "And recall."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uJYA_6jeGPJy",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "recall_score(test_df['digit'], predictions, average='micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eKC9UPWSJFgA"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q_pH3igSFf1D"
      },
      "source": [
        "## Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MeMti4McFyNI"
      },
      "source": [
        "TensorFlow has a [DNNClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) estimator that can also perform classifications. The estimator relies on a deep neural network.\n",
        "\n",
        "Try using the DNNClassifier instead of the [LinearClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier) to identify the MNIST digits that we used in our example code above. Play around with some settings, such as 'hidden_layers' to see if it has any effect on the model.\n",
        "\n",
        "Try using the data as-is and normalized. Do you see any effect?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vgEOtlcUKSxy"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "691Qz6p4k4Xr",
        "colab": {}
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}