{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic Classification Project",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "copyright",
        "exercise-1-key-1",
        "exercise-2-key-1",
        "exercise-3-key-1",
        "exercise-4-key-1"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "copyright"
      },
      "source": [
        "#### Copyright 2019 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Xt6PXeVjxQN",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c2hPzRb6j_CA"
      },
      "source": [
        "# Classification Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fsdfasdfsadfsd"
      },
      "source": [
        "In this project you will apply what you have learned about binary classification and TensorFlow to complete a project from Kaggle. The challenge is to achieve a high accuracy score when trying to predict which passengers survived the Titanic ship crash. After building your model, you will upload your predictions to Kaggle and submit the score that you get."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vaP1zrKmAl2o"
      },
      "source": [
        "## Team\n",
        "\n",
        "Please enter your team members names in the placeholders in this text area:\n",
        "\n",
        "*   *Team Member Placeholder*\n",
        "*   *Team Member Placeholder*\n",
        "*   *Team Member Placeholder*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HDzCkRNv8Kmz"
      },
      "source": [
        "## The Titanic Dataset\n",
        "\n",
        "[Kaggle](https://www.kaggle.com) has a [dataset](https://www.kaggle.com/c/titanic/data) containing the passenger list on the Titanic. The data contains passenger features such as age, gender, ticket class, as well as whether or not they survived.\n",
        "\n",
        "Your job is to create a binary classifier using TensorFlow to determine if a passenger survived or not. Then, upload your predictions to Kaggle and submit your accuracy score at the end of this colab, along with a brief conclusion.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-U_zk4L_HpWJ"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sxmnIepvmdCx"
      },
      "source": [
        "## Exercise 1: Create a Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LO8x9d6GHwgQ"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zKgNoBuEm2h0",
        "colab": {}
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-1-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HASbqtkRHzkI"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hzzf0H2r5F_j",
        "colab": {}
      },
      "source": [
        "# Download the dataset and load the data.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "titanic_df = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/juemura/amli/master/titanic/train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8t4I4pL5_nJD",
        "colab": {}
      },
      "source": [
        "# Look at the description of the dataset to understand the columns.\n",
        "\n",
        "titanic_df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XoBHaAlrGjm-",
        "colab": {}
      },
      "source": [
        "# Examine the dataset format and sample data points.\n",
        "\n",
        "print(titanic_df.dtypes)\n",
        "titanic_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vu5G6j_pAGfV",
        "colab": {}
      },
      "source": [
        "# Perform analysis on the dataset and repair or drop columns and rows of data\n",
        "# as needed.\n",
        "# Are there any missing values?\n",
        "\n",
        "titanic_df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2z0VjHbGAmVe",
        "colab": {}
      },
      "source": [
        "# Do the data values make sense?\n",
        "\n",
        "def titanic_data_prep(df):\n",
        "  # PassengerId is a unique identifier and thus should be used as the index\n",
        "  df.set_index('PassengerId', inplace=True)\n",
        "\n",
        "  # Embarked has 2 null values, we can simply replace them with \"unknown\"\n",
        "  df['Embarked'].fillna('unknown', inplace=True)\n",
        "\n",
        "  # Encode categorical data, i.e. Sex and Embarked\n",
        "  # Among other options, you can use LabelEncoder, One-Hot Encoding, or simply\n",
        "  # replace the values\n",
        "  # For Sex the categories are simple, but for ports we can create a list of\n",
        "  # unique labels and use a dictionary comprehension\n",
        "  port_labels = df['Embarked'].astype('category').cat.categories.tolist()\n",
        "  encoding = {'Sex': {'male': 0, 'female': 1},\n",
        "              'Embarked': {k:v for k,v in zip(port_labels,\n",
        "                                              range(1, len(port_labels)+1))}}\n",
        "  df.replace(encoding, inplace=True)\n",
        "  \n",
        "  # Age has 177 null values that we need to deal with before training our model\n",
        "  # One simple approach is to replace null values with the mean\n",
        "  df.fillna(df.mean(), inplace=True)\n",
        "  \n",
        "  # Name, Ticket, and Cabin are likely irrelevant for our model since they are \n",
        "  # simply identifiers and don't indicate any distinguishing characteristic\n",
        "  df.drop(['Name', 'Ticket', 'Cabin', 'Embarked'], inplace=True, axis=1)\n",
        "\n",
        "titanic_data_prep(titanic_df)\n",
        "\n",
        "# Double check that we got rid of all null values\n",
        "print(titanic_df.isnull().sum())\n",
        "\n",
        "# Check the description of the dataset again to make sure everything looks good \n",
        "titanic_df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HZisbMFxAvrN",
        "colab": {}
      },
      "source": [
        "# Which features seem to be the most important?\n",
        "# Are there highly correlated with each other?\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure()\n",
        "corMat = titanic_df.corr(method='pearson')\n",
        "print(corMat)\n",
        "\n",
        "sns.heatmap(corMat, square=True)\n",
        "plt.yticks(rotation=0)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n",
        "\n",
        "# Observations:\n",
        "# Sex and Fare seem to have the highest correlation with whether or not they \n",
        "# survived, and they are not highly correlated with each other.\n",
        "# Thus they appear to be important features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Savxgg8SAJf3",
        "colab": {}
      },
      "source": [
        "# Split the data into testing and training set.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TARGET = 'Survived'\n",
        "FEATURES = [col for col in titanic_df.columns if col != TARGET]\n",
        "\n",
        "train_df, test_df = train_test_split(\n",
        "  titanic_df,\n",
        "  test_size=0.2,\n",
        ")\n",
        "\n",
        "print(\"Training set shape: {}\".format(train_df.shape))\n",
        "print(\"Test set shape: {}\".format(test_df.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r6F9SgmTAQsJ",
        "colab": {}
      },
      "source": [
        "# Create a tensorflow.estimator.LinearClassifier.\n",
        "\n",
        "from tensorflow.feature_column import numeric_column\n",
        "from tensorflow.estimator import LinearClassifier\n",
        "\n",
        "\n",
        "# Declare the feature columns\n",
        "feature_columns = []\n",
        "\n",
        "for column_name in FEATURES:\n",
        "  feature_columns.append(numeric_column(str(column_name)))\n",
        "\n",
        "for feature in feature_columns:\n",
        "  print(feature)\n",
        "\n",
        "\n",
        "# Check the class count: this should be 2 (survived / didn't survive)\n",
        "class_count = len(train_df[TARGET].unique())\n",
        "print(\"Class count: {}\".format(class_count))\n",
        "\n",
        "\n",
        "# Create a classifier\n",
        "classifier = LinearClassifier(feature_columns=feature_columns,\n",
        "                              n_classes=class_count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ui-pOIL-ASr0",
        "colab": {}
      },
      "source": [
        "# Train the classifier using an input function that feeds the classifier\n",
        "# training data.\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.data import Dataset\n",
        "\n",
        "\n",
        "def training_input():\n",
        "  features = {}\n",
        "  for feature in FEATURES:\n",
        "    features[feature] = train_df[feature]\n",
        "  \n",
        "  labels = train_df[TARGET]\n",
        "\n",
        "  training_ds = Dataset.from_tensor_slices((features, labels))\n",
        "  training_ds = training_ds.shuffle(buffer_size=10000)\n",
        "  training_ds = training_ds.batch(100)\n",
        "  training_ds = training_ds.repeat(5)\n",
        "\n",
        "  return training_ds\n",
        "\n",
        "classifier.train(training_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FvaOtBr_AT9e",
        "colab": {}
      },
      "source": [
        "# Make predictions on the test data using your classifier.\n",
        "\n",
        "def testing_input():\n",
        "  features = {}\n",
        "  for feature in FEATURES:\n",
        "    features[feature] = test_df[feature]\n",
        "  return Dataset.from_tensor_slices((features)).batch(1)\n",
        "\n",
        "predictions_iterator = classifier.predict(testing_input)\n",
        "\n",
        "print(predictions_iterator)\n",
        "\n",
        "predictions_iterator = classifier.predict(testing_input)\n",
        "\n",
        "predictions = [p['class_ids'][0] for p in predictions_iterator]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jWmpzFwPNAcc",
        "colab": {}
      },
      "source": [
        "# Find the accuracy, precision, and recall of your classifier.\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "print(\"Accuracy: {}\".format(accuracy_score(test_df['Survived'], predictions)))\n",
        "\n",
        "print(\"Precision: {}\".format(precision_score(test_df['Survived'], predictions,\n",
        "                                             average='micro')))\n",
        "\n",
        "print(\"Recall: {}\".format(recall_score(test_df['Survived'], predictions,\n",
        "                                       average='micro')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yXJCSsAdz-f0"
      },
      "source": [
        "## Exercise 2: Upload your predictions to Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fijeUn4tIFCo"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dEWZUCnT9UkK",
        "colab": {}
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fRZni-CBVjFV"
      },
      "source": [
        "{### Your written response goes here. Make sure to include your Kaggle score. ###}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-2-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q47q8OjlILQ2"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3n1w0QRP9YhA",
        "colab": {}
      },
      "source": [
        "# Re-run your model using all of the training data.\n",
        "\n",
        "full_train_df = titanic_df\n",
        "\n",
        "print(\"Training set shape: {}\".format(train_df.shape))\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.data import Dataset\n",
        "\n",
        "\n",
        "def training_input():\n",
        "  features = {}\n",
        "  for feature in FEATURES:\n",
        "    features[feature] = full_train_df[feature]\n",
        "  \n",
        "  labels = full_train_df[TARGET]\n",
        "\n",
        "  training_ds = Dataset.from_tensor_slices((features, labels))\n",
        "  training_ds = training_ds.shuffle(buffer_size=10000)\n",
        "  training_ds = training_ds.batch(10)\n",
        "  training_ds = training_ds.repeat(5)\n",
        "\n",
        "  return training_ds\n",
        "\n",
        "classifier.train(training_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J7Uv9Cnano76",
        "colab": {}
      },
      "source": [
        "# Download the test.csv and use it to generate predictions.\n",
        "\n",
        "full_test_df = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/juemura/amli/master/titanic/test.csv')\n",
        "print(\"Test set shape: {}\".format(test_df.shape))\n",
        "\n",
        "titanic_data_prep(full_test_df)\n",
        "\n",
        "def testing_input():\n",
        "  features = {}\n",
        "  for feature in FEATURES:\n",
        "    features[feature] = full_test_df[feature]\n",
        "  return Dataset.from_tensor_slices((features)).batch(1)\n",
        "\n",
        "predictions_iterator = classifier.predict(testing_input)\n",
        "\n",
        "print(predictions_iterator)\n",
        "\n",
        "predictions_iterator = classifier.predict(testing_input)\n",
        "\n",
        "predictions = [p['class_ids'][0] for p in predictions_iterator]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YWjWAdDeurzV",
        "colab": {}
      },
      "source": [
        "# Output the predictions in the format of the gender_submission.csv file.\n",
        "# Download the predictions file from your Colab and upload it to Kaggle.\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'PassengerId': full_test_df.index,\n",
        "    'Survived': predictions,\n",
        "    })\n",
        "results.to_csv('titanic_predictions.csv', index=False)\n",
        "files.download('titanic_predictions.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9KdtnUJP2Uen"
      },
      "source": [
        "## Exercise 3: Improve your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C781-AwN4q9Z"
      },
      "source": [
        "The predictions returned by the LinearClassifer contain scoring and/or confidence information about why the decision was made to classify a passenger as a survivor or not. Find the number used to make the decision and manually play around with different thresholds to build a precision vs. recall chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w5rYKVkgT8NL"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MDEErS0f8oi7",
        "colab": {}
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-3-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SYRk1PknIcdy"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QzI42N4Y9Zkz",
        "colab": {}
      },
      "source": [
        "# TODO(joshmcadams)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QFFInD4j-VMc"
      },
      "source": [
        "## Exercise 4: Dig Deeper (optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "93t_PYx6-W_N"
      },
      "source": [
        "Check out the different approaches in [this kernel](https://www.kaggle.com/startupsci/titanic-data-science-solutions) (kernels are solutions or data exploration notebooks shared by other users).\n",
        "Try using a different approach and see if you can improve your results.\n",
        "\n",
        "Alternatively, you can try implementing a simple decision tree by hand, as in this [Udacity Project](https://github.com/juemura/machine-learning/blob/master/projects/titanic_survival_exploration/titanic_survival_exploration.ipynb). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3_tj2sXDIk7N"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BhbZHXy-ImSj",
        "colab": {}
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-4-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "alWO0aaVIp8v"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jkipr-LlIpEc",
        "colab": {}
      },
      "source": [
        "# TODO(joshmcadams)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}